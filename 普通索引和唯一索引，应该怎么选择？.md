## 普通索引和唯一索引区别

有如下表：

![image](https://img-blog.csdnimg.cn/20200726113926624.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1ZpbmNlX1dhbmcx,size_16,color_FFFFFF,t_70))

![image](https://github.com/whw19970927/Mysql-learning/blob/master/Image/image-20200725233530593.png)

Innodb采用的是聚簇索引，所以左边是主键索引，右边是普通索引。

例：`select id from T where k=5;`

**查询过程：** 

* 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。

* 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

两者性能差距较小，因为innodb是按数据也读取，在16kb一次性的读取中，基本一次性都能读取出需要的数据，所以都是在16kb中查找，性能差距不大。

**更新过程**

* 当需要更新一个数据页时，如果数据页在内存中就直接更新，

* 而如果这个数据页不在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

  

**什么条件下可以使用change buffer**

对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。

因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。



### InnoDB插入一条记录流程

第一种情况是，这个记录要更新的目标页**在内存中**。这时，InnoDB 的处理流程如下：

对于唯一索引，找到 3 和 5 之间的位置，**判断到没有冲突**，插入这个值，语句执行结束；

对于普通索引，找到 3 和 5 之间的位置，插入这个值，语句执行结束。



第二种情况是，这个记录要更新的目标页**不在内存**中。这时，InnoDB 的处理流程如下：

对于唯一索引，需要将数据页读入内存，判断到没有冲突，插入这个值，

对于普通索引，则是将更新记录在 change buffer。



**Q：在change buffer中有此行记录的情况下，再次更改，是增加一条还是原地修改？**

会增加一条，change buffer会记录对某一页做了怎样的修改，如果有新的修改会增加一条数据行



### change buffer 使用场景

**普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？**

* 因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。



* 反之，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。



## 索引选择和实践

### 普通索引和唯一索引性能

这两类索引在查询能力上是没差别的，

主要考虑的是对更新性能的影响。

由于唯一索引用不上 change buffer 的优化机制，因此如果业务可以接受，从性能角度出发建议优先考虑普通索引。

### change buffer 和 redo log 的更新过程

例：`insert into t(id,k) values (id1,k1),(id2,k2);`

![image](https://github.com/whw19970927/Mysql-learning/blob/master/Image/image-20200726000339686.png)

涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。

这条更新语句做了如下的操作（按照图中的数字顺序）： 

1.Page 1 在内存中，直接更新内存；(**任何数据都会先记录redolog，再落盘，所以图中page1即使落入磁盘了，还依然在redo log中有记录**)

2.Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“add(id2, k2) to Page2”这个信息

3.将上述两个动作记入 redo log 中（图中 3 和 4）。做完上面这些，事务就可以完成了。

所以，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。真正数据的修改是在bufferpool的数据页flush到磁盘的时候才会修改



### change buffer和redo log读取过程

执行`select * from t where k in (k1,k2);`

![image](https://github.com/whw19970927/Mysql-learning/blob/master/Image/image-20200726002600051.png)

这里的page1和page2的区别在于，page2上一步被写进了change buffer中。

1.读 Page 1 的时候，直接从内存返回。虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。

2.要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。

change buffer中记录的是对某行记录的一个操作，那么如果获得对应行的操作信息呢，需要遍历吗？如果这样也是很耗时的，其实内部维护了一个哈希表，对应着id的操作。

**redo log** **主要节省的是随机写磁盘的** **IO** **消耗（转成顺序写），而** **change buffer** **主要节省的则是随机读磁盘的** **IO** **消耗。**（有了change buffer就不需要将硬盘中的数据读到内存中再做修改，而是只是记录一个日志到change buffer中，随机读磁盘的io消耗主要出现在更新的时候）



### Merge流程

merge 的执行流程是这样的：

1. 从磁盘读入数据页到内存（老版本的数据页）；

2. 从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；通过hash表判断

3. 写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。



到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据。

## 总结

**Q: 唯一索引 or 普通索引？**

* 首先，业务正确性优先。讨论的前提是“业务代码已经保证不会写入重复数据”的情况下，讨论性能问题。如果业务不能保证，或者业务就是要求数据库来做约束，那么没得选，必须创建唯一索引。这种情况下，本篇文章的意义蜕变成，如果碰上了大量插入数据慢、内存命中率低的时候，可以多提供一个排查思路。 

* 然后，在一些“归档库”的场景，可以考虑使用普通索引。比如，线上数据只需要保留半年，然后历史数据保存在归档库。此时归档数据已经是确保没有唯一键冲突了。要提高归档效率，可以考虑把表里面的唯一索引改成普通索引。

**Q: change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？如果change buffer 丢失，再从磁盘读入数据就没有了 merge 过程，就等于是数据丢失。会不会出现这种情况呢？**

不会丢失。虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。
