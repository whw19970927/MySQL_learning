# 日志和索引相关问题
## 知识回顾
### buffer pool
**概念：** InnnoDB的数据都是放在磁盘上的，而磁盘的速度和CPU的速度之间有难以逾越的鸿沟，为了提升效率，就引入了缓冲池技术，在InnoDB中称之为Buffer Pool。


从磁盘中读取数据的时候，会先将从磁盘中读取到的页放在缓冲池中，这样下次读相同的页的时候，就可以直接从Buffer Pool中获取。


如果只修改了Buffer Pool中的数据而不修改磁盘中数据，这时候就会造成内存和磁盘中数据不一致，这种也叫做**脏页**。


InnoDB 里面有专门的后台线程把 Buffer Pool 的数据写入到磁盘， 每隔一段时间就一次性地把多个修改写入磁盘，这个动作就叫做**刷脏**。


假如我们更新都需要把数据写入数据磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高，怎么办？
   为了解决这个问题，InnoDB就有了redo log,并且采用了Write-Ahead Logging(WAL)方案实现。


### WAL
**概念：** WAL(Write Ahead Log)技术，也称为日志先行的技术，指的是对数据文件进行修改前，必须将修改先记录日志。保证了数据一致性和持久性，并且提升语句执行性能。



**为什么不直接更改磁盘中的数据，而要在内存中更改，然后写日志再落盘这么复杂？**

磁盘的写操作是随机IO，比较消耗性能，如果每次都更新到磁盘，IO成本、查找成本都很高。

如果每次更新都先写入 redo log 中，那么就成了顺序写操作。

而且对于client端，延迟就降低了。


### 核心日志模块
**redo log**

* **InnoDB引擎**特有，当有一条更新记录时，InnodDB会把它先写到redo log，并更新内存，此时更新操作就算完成了。InnoDB会在适当的时候把这个操作记录更新到磁盘，往往是系统比较空闲的时候。


* 固定大小，并且是**循环写**，写满需擦除(确保记录对应内存数据页刷到磁盘中)，擦除期间不接受新请求。


* 保证数据库发生异常重启后，之前提交的记录都不会丢失，这个能力成为**crash-safe**。


![Image](https://img-blog.csdnimg.cn/20200803110323782.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1ZpbmNlX1dhbmcx,size_16,color_FFFFFF,t_70)

这部分内容在[Image](https://github.com/whw19970927/Mysql-learning/blob/master/%E4%B8%80%E6%9D%A1sql%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%882%EF%BC%89.md)中已经有描述


**undo log**

* **回滚**作用



* 多个行版本控制(**MVCC**)，保证事务的原子性

   Multivesion concurrency control（多版本并发控制），并发访问（读或写）数据库时，对正在事务内处理的数据做多版本的管理。以达到用来避免写操作的阻塞，从而引发读操作的并发问题。



* 在数据修改的流程中，会记录一条与当前操作相反的逻辑日志到undo log中（可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录），如果因为某些原因导致事务异常失败了，可以借助该undo log进行回滚，保证事务的完整性，所以undo log也必不可少。

**binlog**

* **server****层**产生，主要记录用户对数据库操作的SQL语句（除了查询语句）


* 可以**追加写**入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。但由于日志可能是基于事务来记录的(如InnoDB表类型)，而事务是绝对不可能也不应该跨文件记录的，如果正好binlog日志文件达到了最大值但事务还没有提交则不会切换新的文件记录，而是继续增大日志，所以 max_binlog_size 指定的值和实际的binlog日志大小不一定相等。

**Q:BINLOG可以简化吗？**
* 如果是主从模式下，binlog是必须的，因为从库的数据同步依赖的就是binlog；


* 如果是单机模式，并且不考虑数据库基于时间点的还原，binlog就不是必须，因为有redo log就可以保证crash-safe能力了；但如果万一需要回滚到某个时间点的状态，这时候就无能为力，所以建议binlog还是一直开启；

根据上面对三个日志的详解，我们可以对这个问题进行解答：在主从模式下，三个日志都是必须的；在单机模式下，binlog可以视情况而定，保险起见最好开启。


### 两阶段提交

![Image](https://img-blog.csdnimg.cn/20200803111544610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1ZpbmNlX1dhbmcx,size_16,color_FFFFFF,t_70)

执行步骤：
* 首先客户端的DML语句传到sever层并进行解析优化
* server层讲优化后的语句传送到innodb存储引擎层开始执行
* 将执行后的结果保存到内存中，并更新redolog，将状态设置为prepare状态
* 状态更新后，innodb层通知server层可以提交事务了
* server层将更新后的状态写入binlog中
* 发起commit指令并提交事务到innodb层
* 最后将本次事务相关的状态设置为commit状态

这里涉及到了两阶段提交，之前也有说过，分为prepare和commit两个阶段，原因是因为binlog在server层，redolog在存储引擎层，两者是两个独立的日志文件，采用两阶段提交就是为了保证数据在逻辑上的一致性，为了后续的数据恢复和主从考虑。

这里会出现两种情况的崩溃

![Image](https://img-blog.csdnimg.cn/20200803141444876.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1ZpbmNlX1dhbmcx,size_16,color_FFFFFF,t_70)

崩溃恢复的判断规则：
*  如果 redo log 里面的事务是完整的，也就是已经有 commit 标识，则直接提交；
* 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整： 
       a. 如果是，则提交事务； 
       b. 否则，回滚事务。

* 时刻A：由于此时binlog还没写，redo log也不会提交，所以崩溃恢复的时候事务会直接回滚。这时候因为binlog没写，所以也不会传到备库。

**Q：那Mysql怎么知道binlog是完整的？**
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200803141730584.png)
一个事务的binlog是有完整的格式的：
* statement格式的binlog最后会有COMMIT
*  row格式的binlog最后有一个XID event

另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的。

**Q：redolog 和 undolog如何关联的？**
它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：

 * 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；

 * 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。

**Q：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?**
在时刻B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。

所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。

其实，两阶段提交是经典的分布式系统问题，并不是 MySQL 独有的。

如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。

**Q：那为什么还需要两阶段提交，把prepare和commit去掉，直接验证redolog和undolog完整性不就行了吗**

两阶段提交是经典的分布式系统的问题，不是Mysql独有的。
对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。

两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交。

**Q：不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？**

答案是不可以。

如果说历史原因的话，那就是 InnoDB 并不是 MySQL 的原生存储引擎。MySQL 的原生引擎是 MyISAM，设计之初就有没有支持崩溃恢复。

InnoDB 在作为 MySQL 的插件加入 MySQL 引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。

InnoDB 接入了 MySQL 后，发现既然 binlog 没有崩溃恢复的能力，那就用 InnoDB 原有的 redo log 好了。

而如果说实现上的原因的话，就有很多了。就按照问题中说的，只用 binlog 来实现崩溃恢复的流程，下图没有 redo log。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200803143114332.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1ZpbmNlX1dhbmcx,size_16,color_FFFFFF,t_70)
这样的流程下，binlog 还是不能支持崩溃恢复的。我说一个不支持的点吧：binlog 没有能力恢复“数据页”。

此时和redolog一点关系都没有了，所以不存在redolog的刷盘机制了，binlog的commit的内容都是在更新在内存中，还没刷到磁盘的时候，binlog2已经crash了，binlog就不会管之前已经commit的binlog1，但binlog1的数据还没刷到磁盘上，所以存在binlog1数据丢失的情况。

所以，至少现在的 binlog 能力，还不能支持崩溃恢复。

**Q：那能不能反过来，只用 redo log，不要 binlog？**

一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。binlog是跟碎写的。
一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。
还有一个是很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的 binlog 来更新自己的数据。

**Q：redo log 一般设置多大？**
之前的图中已经有了，现在一般设置为4个文件，每个文件1gb。

**Q：正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？**

是由buffer pool更新过来的。

实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况。

- 如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。


- 在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。

**Q:redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？**

在一个事务的更新过程中，日志是要写多次的。比如下面这个事务：

```sql
begin;
insert into t1 ...
insert into t2 ...
commit;
```

 



这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。

所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。

但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。

（这里说的是事务执行过程中不会“主动去刷盘”，以减少不必要的 IO 消耗。但是可能会出现“被动写入磁盘”，比如内存不够、其他事务提交等情况。

单独执行一个更新语句的时候，InnoDB 会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成。

